We perform our analysis on the AOL query log~\cite{pass2006picture}, since it is easy to obtain\footnote{the query log can be retrieved from \url{http://www.gregsadetsky.com/aol-data/}}
AOL query log consists of approximately 20 millions of queries submitted by $650,000$ users from March to May in 2006. Queries are normalized (text lowercased, not ascii characters removed) and 
there are in total $10,154,742$ distinct queries. We extracts from the logs two disjunct sets: 
\begin{description}
	\item{\tail{}} the set of the queries in the long tail, containing all the queries that appear in the log with a frequency \emph{lower than or equal} to $2$. The set contains 
	$7,746,607$ distinct queries, the $76\%$ if we look at the distinct queries, but the $26\%$ if we consider repetitions. \diego{I don't know how to write this, total frequency?}
	\item{\head{}} the set of the queries in the head, containing all the queries that appear in the log with a frequency \emph{greater than} to $100$. The set contains 
	$19,953$ distinct queries, the $0.002\%$ if we look at the distinct queries, but still the $26\%$ if we consider repetitions.
\end{description}
The two sets are different in size if we look at the distinct queries but they cover the same fraction of total queries performed by the users. We performed our 
analysis on these two sets.

\paragraph{Enriching the Queries}
We are interested in studying the entities that may occur in queries in order to find if there are connections between the queries in \head{} and in \tail{}.
The Entity Linking task consists in identifying  small fragments of text (that we call \emph{spots}) referring to any entity (represented by a URI) 
within knowledge base. Usually the task is organized in two steps: the i) \textbf{Spot Detection}: given the input document (in our case a query), 
the spots are detected and for each spot a list of candidate entities is retrieved; and the ii) \textbf{Disambiguation}:
for each ambiguous spot (e.g., \texttt{brazil} could refer to the state, or the football team), a single  entity is 
selected  to be linked to the spot.

In this preliminary work we decided to consider only distinct the queries and not the user sessions, and we performed only the first step of the disambiguation 
process, the spot detection. We do not perform the disambiguation for two reasons: i) we are considering only the queries and not all the sessions that contain 
them, so the context is really small and probably not useful for disambiguating correctly the query, and ii) Disambiguation is computationally more expensive, 
while spot detection is performed in $O(t)$, where $t$ is the number of terms in the query, disambiguation is $O(t^2 \cdot c)$ where $c$ is the maximum 
number of entity candidates for a query.   

